{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os.path\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.examples.tutorials.mnist import mnist\n",
    "\n",
    "# Basic model parameters as external flags.\n",
    "FLAGS = None\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "  '--learning_rate',\n",
    "  type=float,\n",
    "  default=0.01,\n",
    "  help='Initial learning rate.'\n",
    ")\n",
    "parser.add_argument(\n",
    "  '--max_steps',\n",
    "  type=int,\n",
    "  default=20000,\n",
    "  help='Number of steps to run trainer.'\n",
    ")\n",
    "parser.add_argument(\n",
    "  '--hidden1',\n",
    "  type=int,\n",
    "  default=128,\n",
    "  help='Number of units in hidden layer 1.'\n",
    ")\n",
    "parser.add_argument(\n",
    "  '--hidden2',\n",
    "  type=int,\n",
    "  default=32,\n",
    "  help='Number of units in hidden layer 2.'\n",
    ")\n",
    "parser.add_argument(\n",
    "  '--batch_size',\n",
    "  type=int,\n",
    "  default=100,\n",
    "  help='Batch size.  Must divide evenly into the dataset sizes.'\n",
    ")\n",
    "parser.add_argument(\n",
    "  '--input_data_dir',\n",
    "  type=str,\n",
    "  default='/tmp/tensorflow/mnist/input_data',\n",
    "  help='Directory to put the input data.'\n",
    ")\n",
    "parser.add_argument(\n",
    "  '--log_dir',\n",
    "  type=str,\n",
    "  default='/tmp/tensorflow/mnist/logs/fully_connected_feed',\n",
    "  help='Directory to put the log data.'\n",
    ")\n",
    "parser.add_argument(\n",
    "  '--fake_data',\n",
    "  default=False,\n",
    "  help='If true, uses fake data for unit testing.',\n",
    "  action='store_true'\n",
    ")\n",
    "\n",
    "FLAGS, unparsed = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\nExtracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\nExtracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\nExtracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\nExtracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Get the sets of images and labels for training, validation, and\n",
    "# test on MNIST.\n",
    "data_sets = input_data.read_data_sets(\"/tmp/tensorflow/mnist/input_data\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_placeholder = tf.placeholder(tf.float32, shape=(100,mnist.IMAGE_PIXELS))\n",
    "labels_placeholder = tf.placeholder(tf.int32, shape=(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "\n",
    "# The MNIST images are always 28x28 pixels.\n",
    "IMAGE_SIZE = 28\n",
    "IMAGE_PIXELS = IMAGE_SIZE * IMAGE_SIZE\n",
    "def inference(images, hidden1_units, hidden2_units):\n",
    "  \"\"\"Build the MNIST model up to where it may be used for inference.\n",
    "  Args:\n",
    "    images: Images placeholder, from inputs().\n",
    "    hidden1_units: Size of the first hidden layer.\n",
    "    hidden2_units: Size of the second hidden layer.\n",
    "  Returns:\n",
    "    softmax_linear: Output tensor with the computed logits.\n",
    "  \"\"\"\n",
    "  # Hidden 1\n",
    "  with tf.name_scope('hidden1'):\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal([IMAGE_PIXELS, hidden1_units],stddev=1.0 / math.sqrt(float(IMAGE_PIXELS))),\n",
    "        name='weights')\n",
    "    biases = tf.Variable(tf.zeros([hidden1_units]),name='biases')\n",
    "    hidden1 = tf.nn.relu(tf.matmul(images, weights) + biases)\n",
    "  # Hidden 2\n",
    "  with tf.name_scope('hidden2'):\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal([hidden1_units, hidden2_units],stddev=1.0 / math.sqrt(float(hidden1_units))),\n",
    "        name='weights')\n",
    "    biases = tf.Variable(tf.zeros([hidden2_units]),name='biases')\n",
    "    hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)\n",
    "  # Linear\n",
    "  with tf.name_scope('softmax_linear'):\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal([hidden2_units, NUM_CLASSES],stddev=1.0 / math.sqrt(float(hidden2_units))),\n",
    "        name='weights')\n",
    "    biases = tf.Variable(tf.zeros([NUM_CLASSES]),name='biases')\n",
    "    logits = tf.matmul(hidden2, weights) + biases\n",
    "  return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Graph that computes predictions from the inference model.\n",
    "logits = mnist.inference(images_placeholder,\n",
    "                         FLAGS.hidden1,\n",
    "                         FLAGS.hidden2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(logits, labels):\n",
    "  \"\"\"Calculates the loss from the logits and the labels.\n",
    "  Args:\n",
    "    logits: Logits tensor, float - [batch_size, NUM_CLASSES].\n",
    "    labels: Labels tensor, int32 - [batch_size].\n",
    "  Returns:\n",
    "    loss: Loss tensor of type float.\n",
    "  \"\"\"\n",
    "  labels = tf.to_int64(labels)\n",
    "  cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels, name='xentropy')\n",
    "  loss = tf.reduce_mean(cross_entropy, name='xentropy_mean')\n",
    "  return loss\n",
    "\n",
    "# Add to the Graph the Ops for loss calculation.\n",
    "loss = mnist.loss(logits, labels_placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(loss, learning_rate):\n",
    "  \"\"\"Sets up the training Ops.\n",
    "  Creates a summarizer to track the loss over time in TensorBoard.\n",
    "  Creates an optimizer and applies the gradients to all trainable variables.\n",
    "  The Op returned by this function is what must be passed to the\n",
    "  `sess.run()` call to cause the model to train.\n",
    "  Args:\n",
    "    loss: Loss tensor, from loss().\n",
    "    learning_rate: The learning rate to use for gradient descent.\n",
    "  Returns:\n",
    "    train_op: The Op for training.\n",
    "  \"\"\"\n",
    "  # Add a scalar summary for the snapshot loss.\n",
    "  tf.summary.scalar('loss', loss)\n",
    "  # Create the gradient descent optimizer with the given learning rate.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "  # Create a variable to track the global step.\n",
    "  global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "  # Use the optimizer to apply the gradients that minimize the loss\n",
    "  # (and also increment the global step counter) as a single training step.\n",
    "  train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "  return train_op\n",
    "\n",
    "# Add to the Graph the Ops that calculate and apply gradients.\n",
    "train_op = mnist.training(loss, FLAGS.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(logits, labels):\n",
    "  \"\"\"Evaluate the quality of the logits at predicting the label.\n",
    "  Args:\n",
    "    logits: Logits tensor, float - [batch_size, NUM_CLASSES].\n",
    "    labels: Labels tensor, int32 - [batch_size], with values in the\n",
    "      range [0, NUM_CLASSES).\n",
    "  Returns:\n",
    "    A scalar int32 tensor with the number of examples (out of batch_size)\n",
    "    that were predicted correctly.\n",
    "  \"\"\"\n",
    "  # For a classifier model, we can use the in_top_k Op.\n",
    "  # It returns a bool tensor with shape [batch_size] that is true for\n",
    "  # the examples where the label is in the top k (here k=1)\n",
    "  # of all logits for that example.\n",
    "  correct = tf.nn.in_top_k(logits, labels, 1)\n",
    "  # Return the number of true entries.\n",
    "  return tf.reduce_sum(tf.cast(correct, tf.int32))\n",
    "\n",
    "# Add the Op to compare the logits to the labels during evaluation.\n",
    "eval_correct = mnist.evaluation(logits, labels_placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the summary Tensor based on the TF collection of Summaries.\n",
    "summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the variable initializer Op.\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a saver for writing training checkpoints.\n",
    "saver = tf.train.Saver(write_version=tf.train.SaverDef.V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a session for running Ops on the Graph.\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a SummaryWriter to output summaries and the Graph.\n",
    "summary_writer = tf.train.SummaryWriter(FLAGS.log_dir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Op to initialize the variables.\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_feed_dict(data_set, images_pl, labels_pl):\n",
    "  \"\"\"Fills the feed_dict for training the given step.\n",
    "  A feed_dict takes the form of:\n",
    "  feed_dict = {\n",
    "      <placeholder>: <tensor of values to be passed for placeholder>,\n",
    "      ....\n",
    "  }\n",
    "  Args:\n",
    "    data_set: The set of images and labels, from input_data.read_data_sets()\n",
    "    images_pl: The images placeholder, from placeholder_inputs().\n",
    "    labels_pl: The labels placeholder, from placeholder_inputs().\n",
    "  Returns:\n",
    "    feed_dict: The feed dictionary mapping from placeholders to values.\n",
    "  \"\"\"\n",
    "  # Create the feed_dict for the placeholders filled with the next\n",
    "  # `batch size` examples.\n",
    "  images_feed, labels_feed = data_set.next_batch(FLAGS.batch_size,\n",
    "                                                 FLAGS.fake_data)\n",
    "  feed_dict = {\n",
    "      images_pl: images_feed,\n",
    "      labels_pl: labels_feed,\n",
    "  }\n",
    "  return feed_dict\n",
    "\n",
    "def do_eval(sess,\n",
    "            eval_correct,\n",
    "            images_placeholder,\n",
    "            labels_placeholder,\n",
    "            data_set):\n",
    "  \"\"\"Runs one evaluation against the full epoch of data.\n",
    "  Args:\n",
    "    sess: The session in which the model has been trained.\n",
    "    eval_correct: The Tensor that returns the number of correct predictions.\n",
    "    images_placeholder: The images placeholder.\n",
    "    labels_placeholder: The labels placeholder.\n",
    "    data_set: The set of images and labels to evaluate, from\n",
    "      input_data.read_data_sets().\n",
    "  \"\"\"\n",
    "  # And run one epoch of eval.\n",
    "  true_count = 0  # Counts the number of correct predictions.\n",
    "  steps_per_epoch = data_set.num_examples // FLAGS.batch_size\n",
    "  num_examples = steps_per_epoch * FLAGS.batch_size\n",
    "  for step in xrange(steps_per_epoch):\n",
    "    feed_dict = fill_feed_dict(data_set,\n",
    "                               images_placeholder,\n",
    "                               labels_placeholder)\n",
    "    true_count += sess.run(eval_correct, feed_dict=feed_dict)\n",
    "  precision = true_count / num_examples\n",
    "  print('  Num examples: %d  Num correct: %d  Precision @ 1: %0.04f' %\n",
    "        (num_examples, true_count, precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: loss = 0.30 (0.021 sec)\nStep 100: loss = 0.13 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200: loss = 0.20 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300: loss = 0.13 (0.120 sec)\nStep 400: loss = 0.13 (0.002 sec)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nStep 500: loss = 0.20 (0.002 sec)\nStep 600: loss = 0.13 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 700: loss = 0.15 (0.002 sec)\nStep 800: loss = 0.10 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 900: loss = 0.14 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Eval:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Num examples: 55000  Num correct: 52900  Precision @ 1: 0.9618\nValidation Data Eval:\n  Num examples: 5000  Num correct: 4809  Precision @ 1: 0.9618\nTest Data Eval:\n  Num examples: 10000  Num correct: 9578  Precision @ 1: 0.9578\nStep 1000: loss = 0.08 (0.020 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1100: loss = 0.09 (0.002 sec)\nStep 1200: loss = 0.13 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1300: loss = 0.12 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1400: loss = 0.07 (0.119 sec)\nStep 1500: loss = 0.12 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1600: loss = 0.05 (0.002 sec)\nStep 1700: loss = 0.08 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1800: loss = 0.15 (0.002 sec)\nStep 1900: loss = 0.18 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Eval:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Num examples: 55000  Num correct: 53015  Precision @ 1: 0.9639\nValidation Data Eval:\n  Num examples: 5000  Num correct: 4817  Precision @ 1: 0.9634\nTest Data Eval:\n  Num examples: 10000  Num correct: 9598  Precision @ 1: 0.9598\nStep 2000: loss = 0.16 (0.016 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2100: loss = 0.14 (0.002 sec)\nStep 2200: loss = 0.11 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2300: loss = 0.27 (0.002 sec)\nStep 2400: loss = 0.15 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500: loss = 0.07 (0.126 sec)\nStep 2600: loss = 0.09 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2700: loss = 0.07 (0.002 sec)\nStep 2800: loss = 0.15 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2900: loss = 0.06 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Eval:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Num examples: 55000  Num correct: 53082  Precision @ 1: 0.9651\nValidation Data Eval:\n  Num examples: 5000  Num correct: 4819  Precision @ 1: 0.9638\nTest Data Eval:\n  Num examples: 10000  Num correct: 9603  Precision @ 1: 0.9603\nStep 3000: loss = 0.04 (0.018 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3100: loss = 0.12 (0.002 sec)\nStep 3200: loss = 0.13 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3300: loss = 0.10 (0.002 sec)\nStep 3400: loss = 0.19 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3500: loss = 0.09 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3600: loss = 0.10 (0.124 sec)\nStep 3700: loss = 0.15 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3800: loss = 0.10 (0.002 sec)\nStep 3900: loss = 0.06 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Eval:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Num examples: 55000  Num correct: 53220  Precision @ 1: 0.9676\nValidation Data Eval:\n  Num examples: 5000  Num correct: 4831  Precision @ 1: 0.9662\nTest Data Eval:\n  Num examples: 10000  Num correct: 9615  Precision @ 1: 0.9615\nStep 4000: loss = 0.24 (0.018 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4100: loss = 0.18 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4200: loss = 0.08 (0.002 sec)\nStep 4300: loss = 0.08 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4400: loss = 0.11 (0.002 sec)\nStep 4500: loss = 0.11 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4600: loss = 0.07 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4700: loss = 0.04 (0.121 sec)\nStep 4800: loss = 0.06 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4900: loss = 0.17 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Eval:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Num examples: 55000  Num correct: 53288  Precision @ 1: 0.9689\nValidation Data Eval:\n  Num examples: 5000  Num correct: 4835  Precision @ 1: 0.9670\nTest Data Eval:\n  Num examples: 10000  Num correct: 9634  Precision @ 1: 0.9634\nStep 5000: loss = 0.03 (0.020 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5100: loss = 0.09 (0.002 sec)\nStep 5200: loss = 0.09 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5300: loss = 0.15 (0.002 sec)\nStep 5400: loss = 0.09 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5500: loss = 0.12 (0.002 sec)\nStep 5600: loss = 0.06 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5700: loss = 0.14 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5800: loss = 0.11 (0.123 sec)\nStep 5900: loss = 0.05 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Eval:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Num examples: 55000  Num correct: 53329  Precision @ 1: 0.9696\nValidation Data Eval:\n  Num examples: 5000  Num correct: 4835  Precision @ 1: 0.9670\nTest Data Eval:\n  Num examples: 10000  Num correct: 9644  Precision @ 1: 0.9644\nStep 6000: loss = 0.14 (0.019 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6100: loss = 0.03 (0.002 sec)\nStep 6200: loss = 0.09 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6300: loss = 0.12 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6400: loss = 0.15 (0.002 sec)\nStep 6500: loss = 0.09 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6600: loss = 0.21 (0.002 sec)\nStep 6700: loss = 0.10 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6800: loss = 0.09 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6900: loss = 0.10 (0.121 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Eval:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Num examples: 55000  Num correct: 53393  Precision @ 1: 0.9708\nValidation Data Eval:\n  Num examples: 5000  Num correct: 4836  Precision @ 1: 0.9672\nTest Data Eval:\n  Num examples: 10000  Num correct: 9648  Precision @ 1: 0.9648\nStep 7000: loss = 0.11 (0.018 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7100: loss = 0.06 (0.002 sec)\nStep 7200: loss = 0.11 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7300: loss = 0.19 (0.002 sec)\nStep 7400: loss = 0.11 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7500: loss = 0.08 (0.002 sec)\nStep 7600: loss = 0.08 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7700: loss = 0.13 (0.002 sec)\nStep 7800: loss = 0.05 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7900: loss = 0.07 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Eval:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Num examples: 55000  Num correct: 53466  Precision @ 1: 0.9721\nValidation Data Eval:\n  Num examples: 5000  Num correct: 4839  Precision @ 1: 0.9678\nTest Data Eval:\n  Num examples: 10000  Num correct: 9654  Precision @ 1: 0.9654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8000: loss = 0.10 (0.138 sec)\nStep 8100: loss = 0.09 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8200: loss = 0.17 (0.002 sec)\nStep 8300: loss = 0.12 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8400: loss = 0.12 (0.002 sec)\nStep 8500: loss = 0.07 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8600: loss = 0.06 (0.002 sec)\nStep 8700: loss = 0.03 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8800: loss = 0.11 (0.002 sec)\nStep 8900: loss = 0.09 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Eval:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Num examples: 55000  Num correct: 53594  Precision @ 1: 0.9744\nValidation Data Eval:\n  Num examples: 5000  Num correct: 4844  Precision @ 1: 0.9688\nTest Data Eval:\n  Num examples: 10000  Num correct: 9672  Precision @ 1: 0.9672\nStep 9000: loss = 0.07 (0.019 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9100: loss = 0.08 (0.118 sec)\nStep 9200: loss = 0.09 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9300: loss = 0.06 (0.002 sec)\nStep 9400: loss = 0.06 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9500: loss = 0.04 (0.002 sec)\nStep 9600: loss = 0.07 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9700: loss = 0.07 (0.002 sec)\nStep 9800: loss = 0.08 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9900: loss = 0.06 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Eval:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Num examples: 55000  Num correct: 53650  Precision @ 1: 0.9755\nValidation Data Eval:\n  Num examples: 5000  Num correct: 4847  Precision @ 1: 0.9694\nTest Data Eval:\n  Num examples: 10000  Num correct: 9678  Precision @ 1: 0.9678\nStep 10000: loss = 0.17 (0.018 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10100: loss = 0.07 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10200: loss = 0.07 (0.128 sec)\nStep 10300: loss = 0.09 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10400: loss = 0.08 (0.002 sec)\nStep 10500: loss = 0.08 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10600: loss = 0.12 (0.002 sec)\nStep 10700: loss = 0.04 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10800: loss = 0.06 (0.002 sec)\nStep 10900: loss = 0.06 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Eval:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Num examples: 55000  Num correct: 53702  Precision @ 1: 0.9764\nValidation Data Eval:\n  Num examples: 5000  Num correct: 4848  Precision @ 1: 0.9696\nTest Data Eval:\n  Num examples: 10000  Num correct: 9689  Precision @ 1: 0.9689\nStep 11000: loss = 0.11 (0.018 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11100: loss = 0.11 (0.002 sec)\nStep 11200: loss = 0.10 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11300: loss = 0.12 (0.125 sec)\nStep 11400: loss = 0.05 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11500: loss = 0.10 (0.002 sec)\nStep 11600: loss = 0.17 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11700: loss = 0.02 (0.002 sec)\nStep 11800: loss = 0.14 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11900: loss = 0.21 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Eval:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Num examples: 55000  Num correct: 53770  Precision @ 1: 0.9776\nValidation Data Eval:\n  Num examples: 5000  Num correct: 4851  Precision @ 1: 0.9702\nTest Data Eval:\n  Num examples: 10000  Num correct: 9694  Precision @ 1: 0.9694\nStep 12000: loss = 0.04 (0.020 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12100: loss = 0.05 (0.002 sec)\nStep 12200: loss = 0.08 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12300: loss = 0.08 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12400: loss = 0.08 (0.122 sec)\nStep 12500: loss = 0.15 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12600: loss = 0.17 (0.002 sec)\nStep 12700: loss = 0.07 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12800: loss = 0.06 (0.002 sec)\nStep 12900: loss = 0.14 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Eval:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Num examples: 55000  Num correct: 53780  Precision @ 1: 0.9778\nValidation Data Eval:\n  Num examples: 5000  Num correct: 4855  Precision @ 1: 0.9710\nTest Data Eval:\n  Num examples: 10000  Num correct: 9699  Precision @ 1: 0.9699\nStep 13000: loss = 0.05 (0.019 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13100: loss = 0.15 (0.002 sec)\nStep 13200: loss = 0.04 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13300: loss = 0.12 (0.002 sec)\nStep 13400: loss = 0.04 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13500: loss = 0.13 (0.127 sec)\nStep 13600: loss = 0.18 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13700: loss = 0.07 (0.002 sec)\nStep 13800: loss = 0.03 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13900: loss = 0.08 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Eval:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Num examples: 55000  Num correct: 53807  Precision @ 1: 0.9783\nValidation Data Eval:\n  Num examples: 5000  Num correct: 4857  Precision @ 1: 0.9714\nTest Data Eval:\n  Num examples: 10000  Num correct: 9699  Precision @ 1: 0.9699\nStep 14000: loss = 0.05 (0.018 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14100: loss = 0.08 (0.002 sec)\nStep 14200: loss = 0.06 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14300: loss = 0.08 (0.002 sec)\nStep 14400: loss = 0.09 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14500: loss = 0.06 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14600: loss = 0.05 (0.124 sec)\nStep 14700: loss = 0.06 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14800: loss = 0.08 (0.002 sec)\nStep 14900: loss = 0.12 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Eval:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Num examples: 55000  Num correct: 53866  Precision @ 1: 0.9794\nValidation Data Eval:\n  Num examples: 5000  Num correct: 4853  Precision @ 1: 0.9706\nTest Data Eval:\n  Num examples: 10000  Num correct: 9710  Precision @ 1: 0.9710\nStep 15000: loss = 0.04 (0.016 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15100: loss = 0.02 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15200: loss = 0.07 (0.002 sec)\nStep 15300: loss = 0.06 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15400: loss = 0.05 (0.002 sec)\nStep 15500: loss = 0.03 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15600: loss = 0.08 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15700: loss = 0.20 (0.118 sec)\nStep 15800: loss = 0.16 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15900: loss = 0.06 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Eval:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Num examples: 55000  Num correct: 53963  Precision @ 1: 0.9811\nValidation Data Eval:\n  Num examples: 5000  Num correct: 4860  Precision @ 1: 0.9720\nTest Data Eval:\n  Num examples: 10000  Num correct: 9718  Precision @ 1: 0.9718\nStep 16000: loss = 0.09 (0.018 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16100: loss = 0.03 (0.002 sec)\nStep 16200: loss = 0.05 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16300: loss = 0.11 (0.002 sec)\nStep 16400: loss = 0.02 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16500: loss = 0.09 (0.002 sec)\nStep 16600: loss = 0.05 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16700: loss = 0.11 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16800: loss = 0.11 (0.126 sec)\nStep 16900: loss = 0.15 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Eval:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Num examples: 55000  Num correct: 53957  Precision @ 1: 0.9810\nValidation Data Eval:\n  Num examples: 5000  Num correct: 4858  Precision @ 1: 0.9716\nTest Data Eval:\n  Num examples: 10000  Num correct: 9714  Precision @ 1: 0.9714\nStep 17000: loss = 0.09 (0.019 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17100: loss = 0.04 (0.002 sec)\nStep 17200: loss = 0.11 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17300: loss = 0.04 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17400: loss = 0.10 (0.002 sec)\nStep 17500: loss = 0.07 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17600: loss = 0.13 (0.003 sec)\nStep 17700: loss = 0.04 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17800: loss = 0.08 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17900: loss = 0.02 (0.118 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Eval:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Num examples: 55000  Num correct: 54014  Precision @ 1: 0.9821\nValidation Data Eval:\n  Num examples: 5000  Num correct: 4857  Precision @ 1: 0.9714\nTest Data Eval:\n  Num examples: 10000  Num correct: 9727  Precision @ 1: 0.9727\nStep 18000: loss = 0.04 (0.018 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18100: loss = 0.05 (0.002 sec)\nStep 18200: loss = 0.03 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18300: loss = 0.07 (0.002 sec)\nStep 18400: loss = 0.04 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18500: loss = 0.08 (0.003 sec)\nStep 18600: loss = 0.06 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18700: loss = 0.06 (0.002 sec)\nStep 18800: loss = 0.02 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18900: loss = 0.05 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Eval:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Num examples: 55000  Num correct: 54079  Precision @ 1: 0.9833\nValidation Data Eval:\n  Num examples: 5000  Num correct: 4857  Precision @ 1: 0.9714\nTest Data Eval:\n  Num examples: 10000  Num correct: 9729  Precision @ 1: 0.9729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19000: loss = 0.04 (0.135 sec)\nStep 19100: loss = 0.03 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19200: loss = 0.04 (0.002 sec)\nStep 19300: loss = 0.03 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19400: loss = 0.04 (0.002 sec)\nStep 19500: loss = 0.07 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19600: loss = 0.11 (0.002 sec)\nStep 19700: loss = 0.06 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19800: loss = 0.05 (0.002 sec)\nStep 19900: loss = 0.03 (0.002 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Eval:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Num examples: 55000  Num correct: 54124  Precision @ 1: 0.9841\nValidation Data Eval:\n  Num examples: 5000  Num correct: 4854  Precision @ 1: 0.9708\nTest Data Eval:\n  Num examples: 10000  Num correct: 9727  Precision @ 1: 0.9727\n"
     ]
    }
   ],
   "source": [
    "# Start the training loop.\n",
    "for step in xrange(FLAGS.max_steps):\n",
    "  start_time = time.time()\n",
    "\n",
    "  # Fill a feed dictionary with the actual set of images and labels\n",
    "  # for this particular training step.\n",
    "  feed_dict = fill_feed_dict(data_sets.train,\n",
    "                             images_placeholder,\n",
    "                             labels_placeholder)\n",
    "\n",
    "  # Run one step of the model.  The return values are the activations\n",
    "  # from the `train_op` (which is discarded) and the `loss` Op.  To\n",
    "  # inspect the values of your Ops or variables, you may include them\n",
    "  # in the list passed to sess.run() and the value tensors will be\n",
    "  # returned in the tuple from the call.\n",
    "  _, loss_value = sess.run([train_op, loss],\n",
    "                           feed_dict=feed_dict)\n",
    "\n",
    "  duration = time.time() - start_time\n",
    "\n",
    "  # Write the summaries and print an overview fairly often.\n",
    "  if step % 100 == 0:\n",
    "    # Print status to stdout.\n",
    "    print('Step %d: loss = %.2f (%.3f sec)' % (step, loss_value, duration))\n",
    "    # Update the events file.\n",
    "    summary_str = sess.run(summary, feed_dict=feed_dict)\n",
    "    summary_writer.add_summary(summary_str, step)\n",
    "    summary_writer.flush()\n",
    "\n",
    "  # Save a checkpoint and evaluate the model periodically.\n",
    "  if (step + 1) % 1000 == 0 or (step + 1) == FLAGS.max_steps:\n",
    "    checkpoint_file = os.path.join(FLAGS.log_dir, 'model.ckpt')\n",
    "    saver.save(sess, checkpoint_file, global_step=step)\n",
    "    # Evaluate against the training set.\n",
    "    print('Training Data Eval:')\n",
    "    do_eval(sess,\n",
    "            eval_correct,\n",
    "            images_placeholder,\n",
    "            labels_placeholder,\n",
    "            data_sets.train)\n",
    "    # Evaluate against the validation set.\n",
    "    print('Validation Data Eval:')\n",
    "    do_eval(sess,\n",
    "            eval_correct,\n",
    "            images_placeholder,\n",
    "            labels_placeholder,\n",
    "            data_sets.validation)\n",
    "    # Evaluate against the test set.\n",
    "    print('Test Data Eval:')\n",
    "    do_eval(sess,\n",
    "            eval_correct,\n",
    "            images_placeholder,\n",
    "            labels_placeholder,\n",
    "            data_sets.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}